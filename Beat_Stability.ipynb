{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Librosa Code License:\n",
        "\n",
        "---\n",
        "\n",
        "ISC License  \n",
        "Copyright (c) 2013--2023, librosa development team.\n",
        "\n",
        "Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n",
        "\n",
        "---\n",
        "\n",
        "**Modifications**: The following code block(s) from the `librosa` library have been modified by Kahyun Choi.\n"
      ],
      "metadata": {
        "id": "fks-z21kvPfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Beat and tempo\n",
        "==============\n",
        ".. autosummary::\n",
        "   :toctree: generated/\n",
        "\n",
        "   beat_track\n",
        "   plp\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats\n",
        "\n",
        "# from librosa_cache import cache\n",
        "from librosa import core\n",
        "from librosa import onset\n",
        "from librosa import util\n",
        "from librosa.feature import tempogram, fourier_tempogram\n",
        "from librosa.feature import tempo as _tempo\n",
        "from librosa.util.exceptions import ParameterError\n",
        "from librosa.util.decorators import moved\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "\n",
        "__all__ = [\"beat_track\", \"tempo\", \"plp\"]\n",
        "\n",
        "\n",
        "tempo = moved(moved_from=\"librosa.beat.tempo\", version=\"0.10.0\", version_removed=\"1.0\")(\n",
        "    _tempo\n",
        ")\n",
        "\n",
        "\n",
        "def beat_track(\n",
        "    *,\n",
        "    y: Optional[np.ndarray] = None,\n",
        "    sr: float = 22050,\n",
        "    onset_envelope: Optional[np.ndarray] = None,\n",
        "    hop_length: int = 512,\n",
        "    start_bpm: float = 120.0,\n",
        "    tightness: float = 100,\n",
        "    trim: bool = True,\n",
        "    bpm: Optional[float] = None,\n",
        "    prior: Optional[scipy.stats.rv_continuous] = None,\n",
        "    units: str = \"frames\",\n",
        ") -> Tuple[float, np.ndarray]:\n",
        "    r\"\"\"Dynamic programming beat tracker.\n",
        "\n",
        "    Beats are detected in three stages, following the method of [#]_:\n",
        "\n",
        "      1. Measure onset strength\n",
        "      2. Estimate tempo from onset correlation\n",
        "      3. Pick peaks in onset strength approximately consistent with estimated\n",
        "         tempo\n",
        "\n",
        "    .. [#] Ellis, Daniel PW. \"Beat tracking by dynamic programming.\"\n",
        "           Journal of New Music Research 36.1 (2007): 51-60.\n",
        "           http://labrosa.ee.columbia.edu/projects/beattrack/\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y : np.ndarray [shape=(n,)] or None\n",
        "        audio time series\n",
        "    sr : number > 0 [scalar]\n",
        "        sampling rate of ``y``\n",
        "    onset_envelope : np.ndarray [shape=(n,)] or None\n",
        "        (optional) pre-computed onset strength envelope.\n",
        "    hop_length : int > 0 [scalar]\n",
        "        number of audio samples between successive ``onset_envelope`` values\n",
        "    start_bpm : float > 0 [scalar]\n",
        "        initial guess for the tempo estimator (in beats per minute)\n",
        "    tightness : float [scalar]\n",
        "        tightness of beat distribution around tempo\n",
        "    trim : bool [scalar]\n",
        "        trim leading/trailing beats with weak onsets\n",
        "    bpm : float [scalar]\n",
        "        (optional) If provided, use ``bpm`` as the tempo instead of\n",
        "        estimating it from ``onsets``.\n",
        "    prior : scipy.stats.rv_continuous [optional]\n",
        "        An optional prior distribution over tempo.\n",
        "        If provided, ``start_bpm`` will be ignored.\n",
        "    units : {'frames', 'samples', 'time'}\n",
        "        The units to encode detected beat events in.\n",
        "        By default, 'frames' are used.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tempo : float [scalar, non-negative]\n",
        "        estimated global tempo (in beats per minute)\n",
        "    beats : np.ndarray [shape=(m,)]\n",
        "        estimated beat event locations in the specified units\n",
        "        (default is frame indices)\n",
        "    .. note::\n",
        "        If no onset strength could be detected, beat_tracker estimates 0 BPM\n",
        "        and returns an empty list.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    ParameterError\n",
        "        if neither ``y`` nor ``onset_envelope`` are provided,\n",
        "        or if ``units`` is not one of 'frames', 'samples', or 'time'\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    librosa.onset.onset_strength\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    Track beats using time series input\n",
        "\n",
        "    >>> y, sr = librosa.load(librosa.ex('choice'), duration=10)\n",
        "\n",
        "    >>> tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    >>> tempo\n",
        "    135.99917763157896\n",
        "\n",
        "    Print the frames corresponding to beats\n",
        "\n",
        "    >>> beats\n",
        "    array([  3,  21,  40,  59,  78,  96, 116, 135, 154, 173, 192, 211,\n",
        "           230, 249, 268, 287, 306, 325, 344, 363])\n",
        "\n",
        "    Or print them as timestamps\n",
        "\n",
        "    >>> librosa.frames_to_time(beats, sr=sr)\n",
        "    array([0.07 , 0.488, 0.929, 1.37 , 1.811, 2.229, 2.694, 3.135,\n",
        "           3.576, 4.017, 4.458, 4.899, 5.341, 5.782, 6.223, 6.664,\n",
        "           7.105, 7.546, 7.988, 8.429])\n",
        "\n",
        "    Track beats using a pre-computed onset envelope\n",
        "\n",
        "    >>> onset_env = librosa.onset.onset_strength(y=y, sr=sr,\n",
        "    ...                                          aggregate=np.median)\n",
        "    >>> tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env,\n",
        "    ...                                        sr=sr)\n",
        "    >>> tempo\n",
        "    135.99917763157896\n",
        "    >>> beats\n",
        "    array([  3,  21,  40,  59,  78,  96, 116, 135, 154, 173, 192, 211,\n",
        "           230, 249, 268, 287, 306, 325, 344, 363])\n",
        "\n",
        "    Plot the beat events against the onset strength envelope\n",
        "\n",
        "    >>> import matplotlib.pyplot as plt\n",
        "    >>> hop_length = 512\n",
        "    >>> fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "    >>> times = librosa.times_like(onset_env, sr=sr, hop_length=hop_length)\n",
        "    >>> M = librosa.feature.melspectrogram(y=y, sr=sr, hop_length=hop_length)\n",
        "    >>> librosa.display.specshow(librosa.power_to_db(M, ref=np.max),\n",
        "    ...                          y_axis='mel', x_axis='time', hop_length=hop_length,\n",
        "    ...                          ax=ax[0])\n",
        "    >>> ax[0].label_outer()\n",
        "    >>> ax[0].set(title='Mel spectrogram')\n",
        "    >>> ax[1].plot(times, librosa.util.normalize(onset_env),\n",
        "    ...          label='Onset strength')\n",
        "    >>> ax[1].vlines(times[beats], 0, 1, alpha=0.5, color='r',\n",
        "    ...            linestyle='--', label='Beats')\n",
        "    >>> ax[1].legend()\n",
        "    \"\"\"\n",
        "    # First, get the frame->beat strength profile if we don't already have one\n",
        "    if onset_envelope is None:\n",
        "        if y is None:\n",
        "            raise ParameterError(\"y or onset_envelope must be provided\")\n",
        "\n",
        "        onset_envelope = onset.onset_strength(\n",
        "            y=y, sr=sr, hop_length=hop_length, aggregate=np.median\n",
        "        )\n",
        "\n",
        "    # Do we have any onsets to grab?\n",
        "    if not onset_envelope.any():\n",
        "        return (0, np.array([], dtype=int))\n",
        "\n",
        "    # Estimate BPM if one was not provided\n",
        "    if bpm is None:\n",
        "        bpm = _tempo(\n",
        "            onset_envelope=onset_envelope,\n",
        "            sr=sr,\n",
        "            hop_length=hop_length,\n",
        "            start_bpm=start_bpm,\n",
        "            prior=prior,\n",
        "        )[0]\n",
        "\n",
        "    # Then, run the tracker\n",
        "    beats, cumscore = __beat_tracker(onset_envelope, bpm, float(sr) / hop_length, tightness, trim)\n",
        "\n",
        "    if units == \"frames\":\n",
        "        return (bpm, beats, cumscore)\n",
        "    elif units == \"samples\":\n",
        "        return (bpm, core.frames_to_samples(beats, hop_length=hop_length))\n",
        "    elif units == \"time\":\n",
        "        return (bpm, core.frames_to_time(beats, hop_length=hop_length, sr=sr))\n",
        "    else:\n",
        "        raise ParameterError(f\"Invalid unit type: {units}\")\n",
        "\n",
        "\n",
        "\n",
        "def plp(\n",
        "    *,\n",
        "    y: Optional[np.ndarray] = None,\n",
        "    sr: float = 22050,\n",
        "    onset_envelope: Optional[np.ndarray] = None,\n",
        "    hop_length: int = 512,\n",
        "    win_length: int = 384,\n",
        "    tempo_min: Optional[float] = 30,\n",
        "    tempo_max: Optional[float] = 300,\n",
        "    prior: Optional[scipy.stats.rv_continuous] = None,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Predominant local pulse (PLP) estimation. [#]_\n",
        "\n",
        "    The PLP method analyzes the onset strength envelope in the frequency domain\n",
        "    to find a locally stable tempo for each frame.  These local periodicities\n",
        "    are used to synthesize local half-waves, which are combined such that peaks\n",
        "    coincide with rhythmically salient frames (e.g. onset events on a musical time grid).\n",
        "    The local maxima of the pulse curve can be taken as estimated beat positions.\n",
        "\n",
        "    This method may be preferred over the dynamic programming method of `beat_track`\n",
        "    when the tempo is expected to vary significantly over time.  Additionally,\n",
        "    since `plp` does not require the entire signal to make predictions, it may be\n",
        "    preferable when beat-tracking long recordings in a streaming setting.\n",
        "\n",
        "    .. [#] Grosche, P., & Muller, M. (2011).\n",
        "        \"Extracting predominant local pulse information from music recordings.\"\n",
        "        IEEE Transactions on Audio, Speech, and Language Processing, 19(6), 1688-1701.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y : np.ndarray [shape=(..., n)] or None\n",
        "        audio time series. Multi-channel is supported.\n",
        "\n",
        "    sr : number > 0 [scalar]\n",
        "        sampling rate of ``y``\n",
        "\n",
        "    onset_envelope : np.ndarray [shape=(..., n)] or None\n",
        "        (optional) pre-computed onset strength envelope\n",
        "\n",
        "    hop_length : int > 0 [scalar]\n",
        "        number of audio samples between successive ``onset_envelope`` values\n",
        "\n",
        "    win_length : int > 0 [scalar]\n",
        "        number of frames to use for tempogram analysis.\n",
        "        By default, 384 frames (at ``sr=22050`` and ``hop_length=512``) corresponds\n",
        "        to about 8.9 seconds.\n",
        "\n",
        "    tempo_min, tempo_max : numbers > 0 [scalar], optional\n",
        "        Minimum and maximum permissible tempo values.  ``tempo_max`` must be at least\n",
        "        ``tempo_min``.\n",
        "\n",
        "        Set either (or both) to `None` to disable this constraint.\n",
        "\n",
        "    prior : scipy.stats.rv_continuous [optional]\n",
        "        A prior distribution over tempo (in beats per minute).\n",
        "        By default, a uniform prior over ``[tempo_min, tempo_max]`` is used.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pulse : np.ndarray, shape=[(..., n)]\n",
        "        The estimated pulse curve.  Maxima correspond to rhythmically salient\n",
        "        points of time.\n",
        "\n",
        "        If input is multi-channel, one pulse curve per channel is computed.\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    beat_track\n",
        "    librosa.onset.onset_strength\n",
        "    librosa.feature.fourier_tempogram\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    Visualize the PLP compared to an onset strength envelope.\n",
        "    Both are normalized here to make comparison easier.\n",
        "\n",
        "    >>> y, sr = librosa.load(librosa.ex('brahms'))\n",
        "    >>> onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "    >>> pulse = librosa.beat.plp(onset_envelope=onset_env, sr=sr)\n",
        "    >>> # Or compute pulse with an alternate prior, like log-normal\n",
        "    >>> import scipy.stats\n",
        "    >>> prior = scipy.stats.lognorm(loc=np.log(120), scale=120, s=1)\n",
        "    >>> pulse_lognorm = librosa.beat.plp(onset_envelope=onset_env, sr=sr,\n",
        "    ...                                  prior=prior)\n",
        "    >>> melspec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "\n",
        "    >>> import matplotlib.pyplot as plt\n",
        "    >>> fig, ax = plt.subplots(nrows=3, sharex=True)\n",
        "    >>> librosa.display.specshow(librosa.power_to_db(melspec,\n",
        "    ...                                              ref=np.max),\n",
        "    ...                          x_axis='time', y_axis='mel', ax=ax[0])\n",
        "    >>> ax[0].set(title='Mel spectrogram')\n",
        "    >>> ax[0].label_outer()\n",
        "    >>> ax[1].plot(librosa.times_like(onset_env),\n",
        "    ...          librosa.util.normalize(onset_env),\n",
        "    ...          label='Onset strength')\n",
        "    >>> ax[1].plot(librosa.times_like(pulse),\n",
        "    ...          librosa.util.normalize(pulse),\n",
        "    ...          label='Predominant local pulse (PLP)')\n",
        "    >>> ax[1].set(title='Uniform tempo prior [30, 300]')\n",
        "    >>> ax[1].label_outer()\n",
        "    >>> ax[2].plot(librosa.times_like(onset_env),\n",
        "    ...          librosa.util.normalize(onset_env),\n",
        "    ...          label='Onset strength')\n",
        "    >>> ax[2].plot(librosa.times_like(pulse_lognorm),\n",
        "    ...          librosa.util.normalize(pulse_lognorm),\n",
        "    ...          label='Predominant local pulse (PLP)')\n",
        "    >>> ax[2].set(title='Log-normal tempo prior, mean=120', xlim=[5, 20])\n",
        "    >>> ax[2].legend()\n",
        "\n",
        "    PLP local maxima can be used as estimates of beat positions.\n",
        "\n",
        "    >>> tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env)\n",
        "    >>> beats_plp = np.flatnonzero(librosa.util.localmax(pulse))\n",
        "    >>> import matplotlib.pyplot as plt\n",
        "    >>> fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "    >>> times = librosa.times_like(onset_env, sr=sr)\n",
        "    >>> ax[0].plot(times, librosa.util.normalize(onset_env),\n",
        "    ...          label='Onset strength')\n",
        "    >>> ax[0].vlines(times[beats], 0, 1, alpha=0.5, color='r',\n",
        "    ...            linestyle='--', label='Beats')\n",
        "    >>> ax[0].legend()\n",
        "    >>> ax[0].set(title='librosa.beat.beat_track')\n",
        "    >>> ax[0].label_outer()\n",
        "    >>> # Limit the plot to a 15-second window\n",
        "    >>> times = librosa.times_like(pulse, sr=sr)\n",
        "    >>> ax[1].plot(times, librosa.util.normalize(pulse),\n",
        "    ...          label='PLP')\n",
        "    >>> ax[1].vlines(times[beats_plp], 0, 1, alpha=0.5, color='r',\n",
        "    ...            linestyle='--', label='PLP Beats')\n",
        "    >>> ax[1].legend()\n",
        "    >>> ax[1].set(title='librosa.beat.plp', xlim=[5, 20])\n",
        "    >>> ax[1].xaxis.set_major_formatter(librosa.display.TimeFormatter())\n",
        "    \"\"\"\n",
        "    # Step 1: get the onset envelope\n",
        "    if onset_envelope is None:\n",
        "        onset_envelope = onset.onset_strength(\n",
        "            y=y, sr=sr, hop_length=hop_length, aggregate=np.median\n",
        "        )\n",
        "\n",
        "    if tempo_min is not None and tempo_max is not None and tempo_max <= tempo_min:\n",
        "        raise ParameterError(\n",
        "            f\"tempo_max={tempo_max} must be larger than tempo_min={tempo_min}\"\n",
        "        )\n",
        "\n",
        "    # Step 2: get the fourier tempogram\n",
        "    ftgram = fourier_tempogram(\n",
        "        onset_envelope=onset_envelope,\n",
        "        sr=sr,\n",
        "        hop_length=hop_length,\n",
        "        win_length=win_length,\n",
        "    )\n",
        "\n",
        "    # Step 3: pin to the feasible tempo range\n",
        "    tempo_frequencies = core.fourier_tempo_frequencies(\n",
        "        sr=sr, hop_length=hop_length, win_length=win_length\n",
        "    )\n",
        "\n",
        "    if tempo_min is not None:\n",
        "        ftgram[..., tempo_frequencies < tempo_min, :] = 0\n",
        "    if tempo_max is not None:\n",
        "        ftgram[..., tempo_frequencies > tempo_max, :] = 0\n",
        "\n",
        "    # reshape lengths to match dimension properly\n",
        "    tempo_frequencies = util.expand_to(tempo_frequencies, ndim=ftgram.ndim, axes=-2)\n",
        "\n",
        "    # Step 3: Discard everything below the peak\n",
        "    ftmag = np.log1p(1e6 * np.abs(ftgram))\n",
        "    if prior is not None:\n",
        "        ftmag += prior.logpdf(tempo_frequencies)\n",
        "\n",
        "    peak_values = ftmag.max(axis=-2, keepdims=True)\n",
        "    ftgram[ftmag < peak_values] = 0\n",
        "\n",
        "    # Normalize to keep only phase information\n",
        "    ftgram /= util.tiny(ftgram) ** 0.5 + np.abs(ftgram.max(axis=-2, keepdims=True))\n",
        "\n",
        "    # Step 5: invert the Fourier tempogram to get the pulse\n",
        "    pulse = core.istft(\n",
        "        ftgram, hop_length=1, n_fft=win_length, length=onset_envelope.shape[-1]\n",
        "    )\n",
        "\n",
        "    # Step 6: retain only the positive part of the pulse cycle\n",
        "    pulse = np.clip(pulse, 0, None, pulse)\n",
        "\n",
        "    # Return the normalized pulse\n",
        "    return util.normalize(pulse, axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "def __beat_tracker(\n",
        "    onset_envelope: np.ndarray, bpm: float, fft_res: float, tightness: float, trim: bool\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Tracks beats in an onset strength envelope.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    onset_envelope : np.ndarray [shape=(n,)]\n",
        "        onset strength envelope\n",
        "    bpm : float [scalar]\n",
        "        tempo estimate\n",
        "    fft_res : float [scalar]\n",
        "        resolution of the fft (sr / hop_length)\n",
        "    tightness : float [scalar]\n",
        "        how closely do we adhere to bpm?\n",
        "    trim : bool [scalar]\n",
        "        trim leading/trailing beats with weak onsets?\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    beats : np.ndarray [shape=(n,)]\n",
        "        frame numbers of beat events\n",
        "    \"\"\"\n",
        "    if bpm <= 0:\n",
        "        raise ParameterError(\"bpm must be strictly positive\")\n",
        "\n",
        "    # convert bpm to a sample period for searching\n",
        "    period = round(60.0 * fft_res / bpm)\n",
        "\n",
        "    # localscore is a smoothed version of AGC'd onset envelope\n",
        "    localscore = __beat_local_score(onset_envelope, period)\n",
        "\n",
        "    # run the DP\n",
        "    backlink, cumscore = __beat_track_dp(localscore, period, tightness)\n",
        "\n",
        "    # get the position of the last beat\n",
        "    beats = [__last_beat(cumscore)]\n",
        "\n",
        "    # Reconstruct the beat path from backlinks\n",
        "    while backlink[beats[-1]] >= 0:\n",
        "        beats.append(backlink[beats[-1]])\n",
        "\n",
        "    # Put the beats in ascending order\n",
        "    # Convert into an array of frame numbers\n",
        "    beats = np.array(beats[::-1], dtype=int)\n",
        "\n",
        "    # Discard spurious trailing beats\n",
        "    beats = __trim_beats(localscore, beats, trim)\n",
        "\n",
        "    return beats, cumscore\n",
        "\n",
        "\n",
        "# -- Helper functions for beat tracking\n",
        "def __normalize_onsets(onsets):\n",
        "    \"\"\"Map onset strength function into the range [0, 1]\"\"\"\n",
        "    norm = onsets.std(ddof=1)\n",
        "    if norm > 0:\n",
        "        onsets = onsets / norm\n",
        "    return onsets\n",
        "\n",
        "\n",
        "def __beat_local_score(onset_envelope, period):\n",
        "    \"\"\"Construct the local score for an onset envlope and given period\"\"\"\n",
        "    window = np.exp(-0.5 * (np.arange(-period, period + 1) * 32.0 / period) ** 2)\n",
        "    return scipy.signal.convolve(__normalize_onsets(onset_envelope), window, \"same\")\n",
        "\n",
        "\n",
        "def __beat_track_dp(localscore, period, tightness):\n",
        "    \"\"\"Core dynamic program for beat tracking\"\"\"\n",
        "    backlink = np.zeros_like(localscore, dtype=int)\n",
        "    cumscore = np.zeros_like(localscore)\n",
        "\n",
        "    # Search range for previous beat\n",
        "    window = np.arange(-2 * period, -np.round(period / 2) + 1, dtype=int)\n",
        "\n",
        "    # Make a score window, which begins biased toward start_bpm and skewed\n",
        "    if tightness <= 0:\n",
        "        raise ParameterError(\"tightness must be strictly positive\")\n",
        "\n",
        "    txwt = -tightness * (np.log(-window / period) ** 2)\n",
        "\n",
        "    # Are we on the first beat?\n",
        "    first_beat = True\n",
        "    for i, score_i in enumerate(localscore):\n",
        "        # Are we reaching back before time 0?\n",
        "        z_pad = np.maximum(0, min(-window[0], len(window)))\n",
        "\n",
        "        # Search over all possible predecessors\n",
        "        candidates = txwt.copy()\n",
        "        candidates[z_pad:] = candidates[z_pad:] + cumscore[window[z_pad:]]\n",
        "\n",
        "        # Find the best preceding beat\n",
        "        beat_location = np.argmax(candidates)\n",
        "\n",
        "        # Add the local score\n",
        "        cumscore[i] = score_i + candidates[beat_location]\n",
        "\n",
        "        # Special case the first onset.  Stop if the localscore is small\n",
        "        if first_beat and score_i < 0.01 * localscore.max():\n",
        "            backlink[i] = -1\n",
        "        else:\n",
        "            backlink[i] = window[beat_location]\n",
        "            first_beat = False\n",
        "\n",
        "        # Update the time range\n",
        "        window = window + 1\n",
        "\n",
        "    return backlink, cumscore\n",
        "\n",
        "\n",
        "def __last_beat(cumscore):\n",
        "    \"\"\"Get the last beat from the cumulative score array\"\"\"\n",
        "    maxes = util.localmax(cumscore)\n",
        "    med_score = np.median(cumscore[np.argwhere(maxes)])\n",
        "\n",
        "    # The last of these is the last beat (since score generally increases)\n",
        "    return np.argwhere((cumscore * maxes * 2 > med_score)).max()\n",
        "\n",
        "\n",
        "def __trim_beats(localscore: np.ndarray, beats: np.ndarray, trim: bool) -> np.ndarray:\n",
        "    \"\"\"Remove spurious leading and trailing beats\"\"\"\n",
        "    smooth_boe = scipy.signal.convolve(localscore[beats], scipy.signal.hann(5), \"same\")\n",
        "\n",
        "    if trim:\n",
        "        threshold = 0.5 * ((smooth_boe**2).mean() ** 0.5)\n",
        "    else:\n",
        "        threshold = 0.0\n",
        "\n",
        "    valid = np.argwhere(smooth_boe > threshold)\n",
        "\n",
        "    return beats[valid.min() : valid.max()]"
      ],
      "metadata": {
        "id": "zB4lZx9fi4JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_beat_stats(y, sr, tightness_score, onset_type, start_bpm):\n",
        "  if onset_type == \"rms\":\n",
        "      onset_env = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]\n",
        "  elif onset_type == \"zcr\":\n",
        "      onset_env = librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=512)[0]\n",
        "  elif onset_type == \"speccent\":\n",
        "      onset_env = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "  elif onset_type == \"onsetstrength\": # Add your technique here\n",
        "      onset_env = librosa.onset.onset_strength(y=y, sr=sr, aggregate=np.median)\n",
        "  else:\n",
        "      raise ValueError(f\"Unknown technique: {onset_type}\")\n",
        "  tempo, beats, cumscore = beat_track(onset_envelope=onset_env, sr=sr, tightness=tightness_score, start_bpm=start_bpm)\n",
        "  return (tempo, beats, cumscore)\n",
        "\n",
        "def select_best_30sec_chunk(index_array_y, sr):\n",
        "    audio_duration = len(index_array_y) / sr\n",
        "    if audio_duration < 30:\n",
        "        print(f\"Warning: Audio is shorter than 30 seconds ({audio_duration} seconds).\")\n",
        "        return 0, len(index_array_y)\n",
        "\n",
        "    # Initialize variables\n",
        "    window_size = 30 * sr  # 30 seconds window\n",
        "    best_start_idx = 0\n",
        "    best_voiced_time = 0\n",
        "    least_long_silence = float('inf')\n",
        "\n",
        "    # Slide window over index_array_y\n",
        "    for start_idx in range(0, len(index_array_y) - window_size, sr):  # Step size is 1 second\n",
        "        end_idx = start_idx + window_size\n",
        "        window = index_array_y[start_idx:end_idx]\n",
        "\n",
        "        # Count voiced time\n",
        "        voiced_time = np.sum(window) / sr\n",
        "\n",
        "        # Count long silences\n",
        "        silence_count = 0\n",
        "        long_silences = 0\n",
        "        for i in range(len(window)):\n",
        "            if window[i] == 0:\n",
        "                silence_count += 1\n",
        "            else:\n",
        "                if silence_count > 2 * sr:  # Consider silences longer than 2 seconds as \"long\"\n",
        "                    long_silences += 1\n",
        "                silence_count = 0\n",
        "\n",
        "        # Update best_start_idx if needed\n",
        "        if voiced_time > best_voiced_time or (voiced_time == best_voiced_time and long_silences < least_long_silence):\n",
        "            best_start_idx = start_idx\n",
        "            best_voiced_time = voiced_time\n",
        "            least_long_silence = long_silences\n",
        "\n",
        "    best_end_idx = best_start_idx + window_size\n",
        "    return best_start_idx, best_end_idx"
      ],
      "metadata": {
        "id": "Ab-p201ejILt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poetry Reading"
      ],
      "metadata": {
        "id": "YLMZPqx2jFgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "from librosa.core import audio\n",
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Assign 'row' with your own dataframe that contains the columns 'Matching_MP3_File', 'transcriptions_list'\n",
        "# row =\n",
        "\n",
        "# Assign the folder path where 'Matching_MP3_File' is located\n",
        "# audio_path =\n",
        "\n",
        "mp3_file_path = audio_path + row['Matching_MP3_File']\n",
        "file_base_name, _ = os.path.splitext(os.path.basename(mp3_file_path))\n",
        "audio_type = 'poetry'\n",
        "\n",
        "\n",
        "y, sr = librosa.load(mp3_file_path, sr=16000)\n",
        "# Initialize an array with zeros\n",
        "index_array_y = np.zeros(len(y))\n",
        "\n",
        "transcriptions = row['transcriptions_list']\n",
        "\n",
        "for segment in transcriptions[\"segments_after_alignment\"]:\n",
        "    for word_info in segment[\"words\"]:\n",
        "        if \"start\" in word_info and \"end\" in word_info:\n",
        "            start_time = word_info[\"start\"]\n",
        "            end_time = word_info[\"end\"]\n",
        "\n",
        "            # Find the sample range corresponding to the word's time interval\n",
        "            start_sample = int(start_time * sr)\n",
        "            end_sample = int(end_time * sr)\n",
        "\n",
        "            # Set to 1 in the index array\n",
        "            index_array_y[start_sample:end_sample] = 1\n",
        "\n",
        "best_start_idx, best_end_idx = select_best_30sec_chunk(index_array_y, sr)\n",
        "print(\"Best 30-second chunk starts at index:\", best_start_idx, \"and ends at index:\", best_end_idx)\n",
        "\n",
        "# Check for various parameter combinations\n",
        "for tightness_score in [1, 1000]:\n",
        "    for onset_type in ['onsetstrength']:\n",
        "        for start_bpm in [120]:\n",
        "          tempo, beats, cumscore = calculate_beat_stats(y[best_start_idx:best_end_idx], sr, tightness_score, onset_type, start_bpm)\n",
        "          # Calculate and print statistics\n",
        "          print(f\"tightness_score: {tightness_score}, Tempo: {tempo}, Cumulative Score / Length: {np.max(cumscore) / len(beats)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb8RHwfzjHrv",
        "outputId": "a7e910e1-df76-4080-da03-374771f2173d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best 30-second chunk starts at index: 80000 and ends at index: 560000\n",
            "tightness_score: 1, Tempo: 110.29411764705883, Cumulative Score / Length: 2.3650420909328327\n",
            "tightness_score: 1000, Tempo: 110.29411764705883, Cumulative Score / Length: 0.941578580463269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1b7c7f2461c4>:509: DeprecationWarning: Importing hann from 'scipy.signal' is deprecated and will raise an error in SciPy 1.13.0. Please use 'scipy.signal.windows.hann' or the convenience function 'scipy.signal.get_window' instead.\n",
            "  smooth_boe = scipy.signal.convolve(localscore[beats], scipy.signal.hann(5), \"same\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Narration"
      ],
      "metadata": {
        "id": "9dcLMKeup6DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "from librosa.core import audio\n",
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Assign 'row' with your own dataframe that contains the columns 'ID', 'READER','BOOK ID', and 'transcriptions_list'\n",
        "# row =\n",
        "\n",
        "# Assign the folder path where a mp3 file is located\n",
        "# audio_path =\n",
        "\n",
        "\n",
        "# Extract ID, Reader, and SUBSET values\n",
        "_id = str(row['ID'])  # Convert to str, in case they are not\n",
        "reader = str(row['READER'])  # Convert to str, in case they are not\n",
        "bookid = row['BOOK ID']\n",
        "\n",
        "file_name = f\"{_id}_{reader}_{bookid}_combined.mp3\"\n",
        "mp3_file_path = os.path.join(audio_path, file_name)\n",
        "\n",
        "file_base_name, _ = os.path.splitext(os.path.basename(mp3_file_path))\n",
        "audio_type = 'narration'\n",
        "\n",
        "\n",
        "y, sr = librosa.load(mp3_file_path, sr=16000)\n",
        "# Initialize an array with zeros\n",
        "index_array_y = np.zeros(len(y))\n",
        "\n",
        "transcriptions = row['transcriptions_list']\n",
        "\n",
        "for segment in transcriptions[\"segments_after_alignment\"]:\n",
        "    for word_info in segment[\"words\"]:\n",
        "        if \"start\" in word_info and \"end\" in word_info:\n",
        "            start_time = word_info[\"start\"]\n",
        "            end_time = word_info[\"end\"]\n",
        "\n",
        "            # Find the sample range corresponding to the word's time interval\n",
        "            start_sample = int(start_time * sr)\n",
        "            end_sample = int(end_time * sr)\n",
        "\n",
        "            # Set to 1 in the index array\n",
        "            index_array_y[start_sample:end_sample] = 1\n",
        "\n",
        "best_start_idx, best_end_idx = select_best_30sec_chunk(index_array_y, sr)\n",
        "print(\"Best 30-second chunk starts at index:\", best_start_idx, \"and ends at index:\", best_end_idx)\n",
        "\n",
        "# Check for various parameter combinations\n",
        "for tightness_score in [1, 1000]:\n",
        "    for onset_type in ['onsetstrength']:\n",
        "        for start_bpm in [120]:\n",
        "          tempo, beats, cumscore = calculate_beat_stats(y[best_start_idx:best_end_idx], sr, tightness_score, onset_type, start_bpm)\n",
        "          # Calculate and print statistics\n",
        "          print(f\"tightness_score: {tightness_score}, Tempo: {tempo}, Cumulative Score / Length: {np.max(cumscore) / len(beats)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI4qyDuJp7dz",
        "outputId": "a87f2c05-1f5a-4993-adc0-07a2d7f5f462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best 30-second chunk starts at index: 1200000 and ends at index: 1680000\n",
            "tightness_score: 1, Tempo: 98.6842105263158, Cumulative Score / Length: 2.9124290948515013\n",
            "tightness_score: 1000, Tempo: 98.6842105263158, Cumulative Score / Length: 1.125259321502782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1b7c7f2461c4>:509: DeprecationWarning: Importing hann from 'scipy.signal' is deprecated and will raise an error in SciPy 1.13.0. Please use 'scipy.signal.windows.hann' or the convenience function 'scipy.signal.get_window' instead.\n",
            "  smooth_boe = scipy.signal.convolve(localscore[beats], scipy.signal.hann(5), \"same\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Singing Voice"
      ],
      "metadata": {
        "id": "2bOLJGZ0p9Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "from librosa.core import audio\n",
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Assign 'row' with your own dataframe that contains the columns 'performance_id', 'transcriptions_list'\n",
        "# row =\n",
        "\n",
        "# Assign the folder path where a mp3 files is located\n",
        "# audio_path =\n",
        "\n",
        "performance_id = row['performance_id']\n",
        "mp3_file_path = os.path.join(audio_path, f\"{performance_id}.mp3\")  # Assuming the filename is performance_id.mp3\n",
        "file_base_name, _ = os.path.splitext(os.path.basename(mp3_file_path))\n",
        "audio_type = 'vocal'\n",
        "\n",
        "y, sr = librosa.load(mp3_file_path, sr=16000)\n",
        "# Initialize an array with zeros\n",
        "index_array_y = np.zeros(len(y))\n",
        "\n",
        "transcriptions = row['transcriptions_list']\n",
        "\n",
        "for segment in transcriptions[\"segments_after_alignment\"]:\n",
        "    for word_info in segment[\"words\"]:\n",
        "        if \"start\" in word_info and \"end\" in word_info:\n",
        "            start_time = word_info[\"start\"]\n",
        "            end_time = word_info[\"end\"]\n",
        "\n",
        "            # Find the sample range corresponding to the word's time interval\n",
        "            start_sample = int(start_time * sr)\n",
        "            end_sample = int(end_time * sr)\n",
        "\n",
        "            # Set to 1 in the index array\n",
        "            index_array_y[start_sample:end_sample] = 1\n",
        "\n",
        "best_start_idx, best_end_idx = select_best_30sec_chunk(index_array_y, sr)\n",
        "print(\"Best 30-second chunk starts at index:\", best_start_idx, \"and ends at index:\", best_end_idx)\n",
        "\n",
        "# Check for various parameter combinations\n",
        "for tightness_score in [1, 1000]:\n",
        "    for onset_type in ['onsetstrength']:\n",
        "        for start_bpm in [120]:\n",
        "          tempo, beats, cumscore = calculate_beat_stats(y[best_start_idx:best_end_idx], sr, tightness_score, onset_type, start_bpm)\n",
        "          # Calculate and print statistics\n",
        "          print(f\"tightness_score: {tightness_score}, Tempo: {tempo}, Cumulative Score / Length: {np.max(cumscore) / len(beats)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtWajBkRp8Ue",
        "outputId": "3205567f-336e-4c4b-f35c-b70ddb278323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best 30-second chunk starts at index: 768000 and ends at index: 1248000\n",
            "tightness_score: 1, Tempo: 170.45454545454547, Cumulative Score / Length: 2.020721899959782\n",
            "tightness_score: 1000, Tempo: 170.45454545454547, Cumulative Score / Length: 0.7784624634142701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1b7c7f2461c4>:509: DeprecationWarning: Importing hann from 'scipy.signal' is deprecated and will raise an error in SciPy 1.13.0. Please use 'scipy.signal.windows.hann' or the convenience function 'scipy.signal.get_window' instead.\n",
            "  smooth_boe = scipy.signal.convolve(localscore[beats], scipy.signal.hann(5), \"same\")\n"
          ]
        }
      ]
    }
  ]
}